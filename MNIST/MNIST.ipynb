{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: zhanghaoyv (zhanghaoyv-henan-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\myprojects\\图像识别基础\\MNIST数据集手写数字识别\\wandb\\run-20240827_152639-iyc85d5j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zhanghaoyv-henan-university/MNIST/runs/iyc85d5j' target=\"_blank\">dark-yogurt-3</a></strong> to <a href='https://wandb.ai/zhanghaoyv-henan-university/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zhanghaoyv-henan-university/MNIST' target=\"_blank\">https://wandb.ai/zhanghaoyv-henan-university/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zhanghaoyv-henan-university/MNIST/runs/iyc85d5j' target=\"_blank\">https://wandb.ai/zhanghaoyv-henan-university/MNIST/runs/iyc85d5j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE=512 #大概需要2G的显存\n",
    "EPOCHS=20 # 总共训练批次\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 让torch判断是否使用GPU，建议使用GPU环境，因为会快很多\n",
    "\n",
    "wandb.init(project=\"MNIST\")\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.001\n",
    "config.epochs = 20\n",
    "config.batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.下载、转换并加载训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=False, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.转换并加载测试集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载测试集\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络模型\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # batch*1*28*28（每次会送入batch个样本，输入通道数1（黑白图像），图像分辨率是28x28）\n",
    "        # 下面的卷积层Conv2d的第一个参数指输入通道数，第二个参数指输出通道数，第三个参数指卷积核的大小\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5) # 输入通道数1，输出通道数10，核的大小5\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3) # 输入通道数10，输出通道数20，核的大小3\n",
    "        # 下面的全连接层Linear的第一个参数指输入通道数，第二个参数指输出通道数\n",
    "        self.fc1 = nn.Linear(20*10*10, 500) # 输入通道数是2000，输出通道数是500\n",
    "        self.fc2 = nn.Linear(500, 10) # 输入通道数是500，输出通道数是10，即10分类\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0) # 在本例中in_size=512，也就是BATCH_SIZE的值。输入的x可以看成是512*1*28*28的张量。\n",
    "\n",
    "        out = self.conv1(x) # batch*1*28*28 -> batch*10*24*24（28x28的图像经过一次核为5x5的卷积，输出变为24x24）\n",
    "        out = F.relu(out) # batch*10*24*24（激活函数ReLU不改变形状））\n",
    "        out = F.max_pool2d(out, 2, 2) # batch*10*24*24 -> batch*10*12*12（2*2的池化层会减半）\n",
    "\n",
    "        out = self.conv2(out) # batch*10*12*12 -> batch*20*10*10（再卷积一次，核的大小是3）\n",
    "        out = F.relu(out) # batch*20*10*10\n",
    "        out = out.view(in_size, -1) # view：拉平（也称拉伸），将二维的图像平铺成一维的，一边进行后边的全连接层。这里是指将二十个通道的10*10的数据全部拉伸并平铺成一个2000维的向量。batch*20*10*10 -> batch*2000（out的第二维是-1，说明是自动推算，本例中第二维是20*10*10）\n",
    "\n",
    "        out = self.fc1(out) # 全连接层：batch*2000 -> batch*500\n",
    "        out = F.relu(out) # batch*500\n",
    "\n",
    "        out = self.fc2(out) # batch*500 -> batch*10\n",
    "        \n",
    "        out = F.log_softmax(out, dim=1) # 计算log(softmax(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.网络模型图解\n",
    "<div style=\"white-space: nowrap; overflow-x: auto;\">\n",
    "    <img src=\"IMG_0085.jpeg\" alt=\"Image 1\" style=\"display: inline-block; width: 1050px; height: auto;\">\n",
    "    <img src=\"IMG_0086.jpeg\" alt=\"Image 2\" style=\"display: inline-block; width: 1050px; height: auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "model = ConvNet().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.定义训练方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练方法\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train() # 将模型设置为训练模式\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): # batch_idx是指某个batch的下标（从0开始），data 是从 train_loader 加载的一批训练样本，包含一个批次的数据\n",
    "        data, target = data.to(device), target.to(device) # 部署到DEVICE上\n",
    "        optimizer.zero_grad() # 梯度初始化为0\n",
    "        output = model(data) # 将数据传递给模型，得到模型的预测输出\n",
    "        loss = F.nll_loss(output, target) # 计算负对数似然损失\n",
    "        loss.backward() # 反向传播，计算损失相对于模型参数的梯度\n",
    "        optimizer.step() # 更新参数\n",
    "        # 打印结果\n",
    "        if(batch_idx+1)%30 == 0: # 每训练30个批次，打印一次当前的训练进度和损失值\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( # 分别保留0位小数和6位小数\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            wandb.log({\"Train Loss\": loss.item(), \"epoch\": epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.定义测试方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试方法\n",
    "def test(model, device, test_loader):\n",
    "    model.eval() # 将模型设置为评估模式，这种模式下会关闭 Dropout 并使用全局均值和方差，而不是批次的均值和方差。\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # 上下文管理器，用于禁用梯度计算。\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # target 是实际的类别标签，通常是一个形状为 (batch_size,) 的一维张量。view_as(pred) 将 target 的形状调整为与 pred 相同的形状 (batch_size, 1)，以便进行元素级的比较。eq 是 PyTorch 的元素级比较操作，它将 pred 和调整后的 target 逐元素进行比较，返回一个布尔张量，表示每个预测是否正确。\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    wandb.log({\"Test Loss\": test_loss, \"Correct\": correct, \"Accuracy\": 1. * correct / len(test_loader.dataset)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注：<p style=\"color: pink; font-family: Arial\">对上述“test()”的解释</p>\n",
    "## <p style=\"color: orange; font-family: Arial\">pred = output.max(1, keepdim=True)[1]</p>\n",
    "1. output 是模型的预测输出，通常是一个二维张量，形状为 (batch_size, num_classes)，其中 batch_size 是批次大小（即有batch_size行0~9的概率的样本），num_classes 是类别数（即0的概率，1的概率，……，9的概率）。\n",
    "2. max(1, keepdim=True) 操作在 output 张量的第一个维度（即batch_size）上寻找最大值。\n",
    "   - 1 代表沿着第一个维度（即每行）中寻找最大值。\n",
    "   - keepdim=True 表示保持输出的维度不变，即返回的结果仍然是一个二维张量。有几层中括号嵌套就有几个维度（如 [12,32] 是一维张量，而 [[12],[32]] 就是二维张量）。\n",
    "   - 这个操作返回两个张量：\n",
    "     - 最大值本身。（索引为0）\n",
    "     - 最大值所在的索引。（即对应的类别，索引为1）\n",
    "3. [1]\n",
    "   - [1] 选择了 max 操作返回的第二个张量，即最大值索引的张量。\n",
    "   - 这个张量 pred 的形状为 (batch_size, 1)，其中每个元素是该样本的预测类别索引。\n",
    "## <p style=\"color: orange; font-family: Arial\">correct += pred.eq(target.view_as(pred)).sum().item()</p>\n",
    "1. target.view_as(pred)将 target 的形状调整为与 pred 相同的形状 (batch_size, 1)，以便进行元素级的比较。\n",
    "2. eq 是 PyTorch 的元素级比较操作，它将 pred 和调整后的 target 逐元素进行比较，返回一个布尔张量，表示每个预测是否正确。\n",
    "3. sum() 将布尔张量中的 True 值求和，得到预测正确的样本数。（得到的结果是只有一个数的标量张量，如在本例中可能为[9973],即预测正确的个数）（在 Python 中，True 相当于 1，False 相当于 0）\n",
    "4. item() 将这个标量张量转换为普通的 Python 数值（整数型，如 [9973] -> 9973），以便累加到 correct 变量中。\n",
    "5. 最终得到的 correct 是预测正确的总个数，而不是正确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.204200\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.179580\n",
      "Train Epoch: 1 [45568/60000 (75%)]\tLoss: 0.143057\n",
      "\n",
      "Test set: Average loss: 0.1015, Accuracy: 9702/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 0.089971\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 0.136035\n",
      "Train Epoch: 2 [45568/60000 (75%)]\tLoss: 0.063164\n",
      "\n",
      "Test set: Average loss: 0.0525, Accuracy: 9824/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 0.072219\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 0.044464\n",
      "Train Epoch: 3 [45568/60000 (75%)]\tLoss: 0.086098\n",
      "\n",
      "Test set: Average loss: 0.0415, Accuracy: 9863/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 0.044061\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 0.023826\n",
      "Train Epoch: 4 [45568/60000 (75%)]\tLoss: 0.036759\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 9882/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 0.028292\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.029318\n",
      "Train Epoch: 5 [45568/60000 (75%)]\tLoss: 0.046315\n",
      "\n",
      "Test set: Average loss: 0.0384, Accuracy: 9876/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [14848/60000 (25%)]\tLoss: 0.005703\n",
      "Train Epoch: 6 [30208/60000 (50%)]\tLoss: 0.033774\n",
      "Train Epoch: 6 [45568/60000 (75%)]\tLoss: 0.010481\n",
      "\n",
      "Test set: Average loss: 0.0367, Accuracy: 9878/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [14848/60000 (25%)]\tLoss: 0.008468\n",
      "Train Epoch: 7 [30208/60000 (50%)]\tLoss: 0.022544\n",
      "Train Epoch: 7 [45568/60000 (75%)]\tLoss: 0.018185\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [14848/60000 (25%)]\tLoss: 0.010875\n",
      "Train Epoch: 8 [30208/60000 (50%)]\tLoss: 0.007116\n",
      "Train Epoch: 8 [45568/60000 (75%)]\tLoss: 0.009068\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 9916/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [14848/60000 (25%)]\tLoss: 0.012738\n",
      "Train Epoch: 9 [30208/60000 (50%)]\tLoss: 0.017007\n",
      "Train Epoch: 9 [45568/60000 (75%)]\tLoss: 0.015878\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [14848/60000 (25%)]\tLoss: 0.012875\n",
      "Train Epoch: 10 [30208/60000 (50%)]\tLoss: 0.013908\n",
      "Train Epoch: 10 [45568/60000 (75%)]\tLoss: 0.006286\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [14848/60000 (25%)]\tLoss: 0.001731\n",
      "Train Epoch: 11 [30208/60000 (50%)]\tLoss: 0.004002\n",
      "Train Epoch: 11 [45568/60000 (75%)]\tLoss: 0.003541\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [14848/60000 (25%)]\tLoss: 0.009506\n",
      "Train Epoch: 12 [30208/60000 (50%)]\tLoss: 0.002896\n",
      "Train Epoch: 12 [45568/60000 (75%)]\tLoss: 0.002197\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [14848/60000 (25%)]\tLoss: 0.003627\n",
      "Train Epoch: 13 [30208/60000 (50%)]\tLoss: 0.003455\n",
      "Train Epoch: 13 [45568/60000 (75%)]\tLoss: 0.002276\n",
      "\n",
      "Test set: Average loss: 0.0352, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [14848/60000 (25%)]\tLoss: 0.004229\n",
      "Train Epoch: 14 [30208/60000 (50%)]\tLoss: 0.013013\n",
      "Train Epoch: 14 [45568/60000 (75%)]\tLoss: 0.002499\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [14848/60000 (25%)]\tLoss: 0.000669\n",
      "Train Epoch: 15 [30208/60000 (50%)]\tLoss: 0.012347\n",
      "Train Epoch: 15 [45568/60000 (75%)]\tLoss: 0.001428\n",
      "\n",
      "Test set: Average loss: 0.0322, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [14848/60000 (25%)]\tLoss: 0.001442\n",
      "Train Epoch: 16 [30208/60000 (50%)]\tLoss: 0.001339\n",
      "Train Epoch: 16 [45568/60000 (75%)]\tLoss: 0.001818\n",
      "\n",
      "Test set: Average loss: 0.0341, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [14848/60000 (25%)]\tLoss: 0.002753\n",
      "Train Epoch: 17 [30208/60000 (50%)]\tLoss: 0.001014\n",
      "Train Epoch: 17 [45568/60000 (75%)]\tLoss: 0.006723\n",
      "\n",
      "Test set: Average loss: 0.0347, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [14848/60000 (25%)]\tLoss: 0.002732\n",
      "Train Epoch: 18 [30208/60000 (50%)]\tLoss: 0.000832\n",
      "Train Epoch: 18 [45568/60000 (75%)]\tLoss: 0.000606\n",
      "\n",
      "Test set: Average loss: 0.0312, Accuracy: 9916/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [14848/60000 (25%)]\tLoss: 0.000112\n",
      "Train Epoch: 19 [30208/60000 (50%)]\tLoss: 0.000220\n",
      "Train Epoch: 19 [45568/60000 (75%)]\tLoss: 0.000943\n",
      "\n",
      "Test set: Average loss: 0.0394, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [14848/60000 (25%)]\tLoss: 0.002665\n",
      "Train Epoch: 20 [30208/60000 (50%)]\tLoss: 0.000370\n",
      "Train Epoch: 20 [45568/60000 (75%)]\tLoss: 0.002034\n",
      "\n",
      "Test set: Average loss: 0.0352, Accuracy: 9921/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e85b408344f4a86940bca00c77e5438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▅▆▇▇▇▇█▇▇█▇▇██▇▇███</td></tr><tr><td>Correct</td><td>▁▅▆▇▇▇▇█▇▇█▇▇██▇▇███</td></tr><tr><td>Test Loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▂▁▁▂▂▁▂▂</td></tr><tr><td>Train Loss</td><td>█▇▄▆▃▃▃▂▂▂▁▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.9921</td></tr><tr><td>Correct</td><td>9921</td></tr><tr><td>Test Loss</td><td>0.03524</td></tr><tr><td>Train Loss</td><td>0.00203</td></tr><tr><td>epoch</td><td>20</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-yogurt-3</strong> at: <a href='https://wandb.ai/zhanghaoyv-henan-university/MNIST/runs/iyc85d5j' target=\"_blank\">https://wandb.ai/zhanghaoyv-henan-university/MNIST/runs/iyc85d5j</a><br/> View project at: <a href='https://wandb.ai/zhanghaoyv-henan-university/MNIST' target=\"_blank\">https://wandb.ai/zhanghaoyv-henan-university/MNIST</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240827_152639-iyc85d5j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)\n",
    "\n",
    "wandb.finish()\n",
    "# 耗时1m40s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.查看卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 选择要查看的卷积层\n",
    "conv_layer = model.conv1\n",
    "\n",
    "# 获取卷积核的权重\n",
    "kernels = conv_layer.weight.data.cpu()\n",
    "\n",
    "# 如果需要，可以选择将卷积核可视化\n",
    "# 这里我们展示第一个卷积核的第一个通道\n",
    "kernel = kernels[0, 0, :, :]\n",
    "\n",
    "plt.imshow(kernel, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.06152695  0.03152335 -0.12073006  0.11741224 -0.1225052 ]\n",
      "   [ 0.0737172   0.22378097  0.18335472  0.03701213 -0.01067862]\n",
      "   [ 0.2662688   0.1438023   0.17070056  0.27754807  0.00772829]\n",
      "   [-0.1076635  -0.21997023 -0.24198417  0.00843272  0.16523086]\n",
      "   [ 0.08079229 -0.06974088 -0.21124376 -0.20694977 -0.2390114 ]]]\n",
      "\n",
      "\n",
      " [[[-0.2610012  -0.25657606  0.07575312 -0.12223057 -0.12266198]\n",
      "   [-0.1311515  -0.1230423  -0.09677983 -0.10736368 -0.20514372]\n",
      "   [ 0.08782323 -0.14257543  0.03613168 -0.0131584   0.00098582]\n",
      "   [ 0.27116665  0.03021513 -0.07362312  0.07417988  0.16883011]\n",
      "   [-0.07567716  0.26418895 -0.01190767 -0.15144494 -0.13621543]]]\n",
      "\n",
      "\n",
      " [[[ 0.04381867  0.02874119 -0.01326578 -0.11084831  0.21168226]\n",
      "   [ 0.04873326  0.04401327  0.1642342   0.24968657  0.22604449]\n",
      "   [-0.06182399  0.13544163 -0.08584588 -0.11422095 -0.0741    ]\n",
      "   [-0.06215561 -0.11856619 -0.11896507 -0.13129945 -0.279226  ]\n",
      "   [-0.1278965  -0.07958227 -0.07162569 -0.05924967  0.03401191]]]\n",
      "\n",
      "\n",
      " [[[ 0.04096128 -0.11302284  0.00905589  0.03889211  0.25567314]\n",
      "   [-0.03005789  0.08599225  0.22314645  0.11705236 -0.04972259]\n",
      "   [-0.15629816  0.13110699  0.14018664  0.23350018  0.07522426]\n",
      "   [ 0.08339868 -0.09765223  0.1892666   0.18329345  0.04428861]\n",
      "   [ 0.10690472 -0.17650329  0.21050718 -0.08949549  0.02574136]]]\n",
      "\n",
      "\n",
      " [[[ 0.16131043  0.07479107 -0.16028    -0.10882553 -0.3040262 ]\n",
      "   [ 0.23548692  0.18038182  0.05986033  0.02026392 -0.28029135]\n",
      "   [-0.1440481   0.2988107  -0.06183933  0.07388108 -0.25206268]\n",
      "   [-0.04851368  0.01934554  0.21165594 -0.11556365 -0.25365368]\n",
      "   [-0.05405312  0.1579016   0.13870731 -0.22845909 -0.06747365]]]\n",
      "\n",
      "\n",
      " [[[ 0.3051069   0.06688065  0.09981643  0.02649919  0.16944182]\n",
      "   [ 0.12853862 -0.08232572  0.20782867 -0.14204179 -0.00609267]\n",
      "   [ 0.27637258  0.14463475 -0.21164314 -0.18720102 -0.21053705]\n",
      "   [ 0.19557904 -0.23606089 -0.21587075 -0.20679621  0.05279302]\n",
      "   [-0.11672717 -0.22313647 -0.24948701 -0.10475714 -0.0669305 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.19586885 -0.12168953 -0.3019292  -0.00333671  0.05734457]\n",
      "   [ 0.06382757  0.04915816 -0.30094177 -0.17841992 -0.17841451]\n",
      "   [ 0.16711059  0.02805751 -0.13424936 -0.05479906  0.0229837 ]\n",
      "   [ 0.31967792  0.19295567  0.10252184 -0.22842202 -0.02731669]\n",
      "   [-0.06241785  0.1890644   0.2927699   0.04215727  0.02613993]]]\n",
      "\n",
      "\n",
      " [[[-0.14247231 -0.1540348   0.16420534  0.03715472  0.13177393]\n",
      "   [-0.15294892  0.08601772  0.12122662  0.2673532  -0.00714168]\n",
      "   [ 0.06242485 -0.26557642  0.04808985  0.18912737  0.2678376 ]\n",
      "   [ 0.20029351 -0.21356104 -0.26674175 -0.3743823  -0.15144189]\n",
      "   [ 0.19723178  0.2000362  -0.07122155 -0.24349482 -0.15879168]]]\n",
      "\n",
      "\n",
      " [[[ 0.1894988   0.00380158  0.15886039  0.02311253  0.19259624]\n",
      "   [-0.17042597  0.03831303 -0.04716452  0.10250904 -0.07553366]\n",
      "   [-0.14337231  0.08815423  0.08729268  0.26768458 -0.2109581 ]\n",
      "   [-0.29973602 -0.08739349  0.07378212  0.00513086 -0.10038884]\n",
      "   [ 0.03385666  0.1774616   0.23014876 -0.07355116  0.18060663]]]\n",
      "\n",
      "\n",
      " [[[-0.1159211  -0.17725582 -0.24412432 -0.00368771 -0.02320679]\n",
      "   [-0.07475662  0.01769564  0.06921774  0.15848595  0.04904157]\n",
      "   [ 0.034531    0.11597489  0.01647704  0.22151184  0.02276649]\n",
      "   [ 0.11718291  0.22413562  0.0498033   0.1160059  -0.20522302]\n",
      "   [ 0.09293617  0.22175387  0.01240505 -0.29469162 -0.20757665]]]]\n",
      "卷积核的形状: (10, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# 选择你要查看的卷积层，例如 model.conv1\n",
    "conv_layer = model.conv1\n",
    "\n",
    "# 获取卷积核的权重\n",
    "kernels = conv_layer.weight.data.cpu().numpy()\n",
    "\n",
    "# 查看卷积核的权重\n",
    "print(kernels)\n",
    "\n",
    "# 查看卷积核形状\n",
    "print(\"卷积核的形状:\", kernels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "limuDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
